#pragma kernel OrInt OR SUFFIX=OrInt
#pragma kernel AndInt AND SUFFIX=AndInt
#pragma kernel XorInt XOR SUFFIX=XorInt

#pragma kernel IsInf

#include "Tensor.cginc"

int shapeO[8];
int stridesO[8];
int shapeA[8];
int stridesA[8];
int shapeB[8];
int stridesB[8];
uint2 unrolledDispatchArgs;
int rank;
bool detectNegative;
bool detectPositive;

StructuredBuffer<int> Xptr;
StructuredBuffer<int> Bptr;
RWStructuredBuffer<int> Optr;

inline int CompareOp(int x, int y)
{
#ifdef OR
    return x | y;
#endif
#ifdef AND
    return x & y;
#endif
#ifdef XOR
    return x ^ y;
#endif
    return 0;
}

[numthreads(64, 1, 1)]
void SUFFIX(uint3 dispatchThreadID : SV_DispatchThreadID)
{
    uint threadIdx = unrolledDispatchArgs.x * dispatchThreadID.y + dispatchThreadID.x;
    if (threadIdx >= unrolledDispatchArgs.y)
        return;

    int indexA = 0; int indexB = 0;
    for (int axis = 0; axis < rank; axis++)
    {
        indexA += (((threadIdx / stridesO[(SHAPE_MAXRANK - 1) - axis]) % shapeO[(SHAPE_MAXRANK - 1) - axis]) % shapeA[(SHAPE_MAXRANK - 1) - axis]) * stridesA[(SHAPE_MAXRANK - 1) - axis];
        indexB += (((threadIdx / stridesO[(SHAPE_MAXRANK - 1) - axis]) % shapeO[(SHAPE_MAXRANK - 1) - axis]) % shapeB[(SHAPE_MAXRANK - 1) - axis]) * stridesB[(SHAPE_MAXRANK - 1) - axis];
    }

    int a = Xptr[indexA];
    int b = Bptr[indexB];

    Optr[threadIdx] = CompareOp(a, b);
}

#define TILE_DIM 256

StructuredBuffer<float> X_float_ptr;

[numthreads(TILE_DIM, 1, 1)]
void IsInf(uint3 dispatchThreadID : SV_DispatchThreadID, uint3 groupThreadID : SV_GroupThreadID, uint threadIndex : SV_GroupIndex, uint3 groupID : SV_GroupID)
{
    uint groupLengthX = unrolledDispatchArgs.x;
    uint totalLength = unrolledDispatchArgs.y;

    uint ti = threadIndex + TILE_DIM * (groupID.x + groupID.y * groupLengthX);
    if (ti >= totalLength)
        return;

    float v = X_float_ptr[ti];
    Optr[ti] = isinf(v) && ((v > 0 && detectPositive) || (v < 0 && detectNegative)) ? 1 : 0;
}
